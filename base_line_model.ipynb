{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "base_line_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHu5u4wQwZVW3AEHJOOUD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohEder/bachelor_thesis_audio_ml/blob/master/base_line_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Vvaf0GA9sS",
        "outputId": "2290da02-fa86-4283-96a1-c82b46430e16"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/20/eab40caad8f4b97f5e91a5de8ba5ec29115e08fa4c9a808725490b7b4844/torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 21.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 22.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 17.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 12.8MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 10.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 11.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 12.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 12.2MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 12.2MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 12.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 12.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 12.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153kB 12.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163kB 12.2MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 12.2MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225kB 12.2MB/s eta 0:00:01\r\u001b[K     |████                            | 235kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276kB 12.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 409kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 419kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 450kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 471kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 522kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 542kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 563kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 614kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 634kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 665kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 675kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 686kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 727kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 747kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 757kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 778kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 788kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 798kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 819kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 839kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 849kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 860kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 870kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 880kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 901kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 911kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 931kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 942kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 962kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 972kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 983kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 993kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9MB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og7X9VAnBFWh"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset \n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48fmEM6z19xX"
      },
      "source": [
        "#just copied the official import script for the dataset, custom preprocessing happens afterwards\n",
        "\"\"\" Import script for IDMT-Traffic dataset\n",
        "Ref:\n",
        "    J. Abeßer, S. Gourishetti, A. Kátai, T. Clauß, P. Sharma, J. Liebetrau: IDMT-Traffic: An Open Benchmark\n",
        "    Dataset for Acoustic Traffic Monitoring Research, EUSIPCO, 2021\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "__author__ = 'Jakob Abeßer (jakob.abesser@idmt.fraunhofer.de)'\n",
        "\n",
        "\n",
        "def import_idmt_traffic_dataset(fn_txt: str = \"idmt_traffic_all\") -> pd.DataFrame:\n",
        "    \"\"\" Import IDMT-Traffic dataset\n",
        "    Args:\n",
        "        fn_txt (str): Text file with all WAV files\n",
        "    Returns:\n",
        "        df_dataset (pd.Dataframe): File-wise metadata\n",
        "            Columns:\n",
        "                'file': WAV filename,\n",
        "                'is_background': True if recording contains background noise (no vehicle), False else\n",
        "                'date_time': Recording time (YYYY-MM-DD-HH-mm)\n",
        "                'location': Recording location\n",
        "                'speed_kmh': Speed limit at recording site (km/h), UNK if unknown,\n",
        "                'sample_pos': Sample position (centered) within the original audio recording,\n",
        "                'daytime': M(orning) or (A)fternoon,\n",
        "                'weather': (D)ry or (W)et road condition,\n",
        "                'vehicle': (B)us, (C)ar, (M)otorcycle, or (T)ruck,\n",
        "                'source_direction': Source direction of passing vehicle: from (L)eft or from (R)ight,\n",
        "                'microphone': (SE)= (high-quality) sE8 microphones, (ME) = (low-quality) MEMS microphones (ICS-43434),\n",
        "                'channel': Original stereo pair channel (12) or (34)\n",
        "    \"\"\"\n",
        "    # load file list\n",
        "    df_files = pd.read_csv(fn_txt, names=('file',))\n",
        "    fn_file_list = df_files['file'].to_list()\n",
        "\n",
        "    # load metadata from file names\n",
        "    df_dataset = []\n",
        "\n",
        "    for f, fn in enumerate(fn_file_list):\n",
        "        fn = fn.replace('.wav', '')\n",
        "        parts = fn.split('_')\n",
        "\n",
        "        # background noise files\n",
        "        if '-BG' in fn:\n",
        "            date_time, location, speed_kmh, sample_pos, mic, channel = parts\n",
        "            vehicle, source_direction, weather, daytime = 'None', 'None', 'None', 'None'\n",
        "            is_background = True\n",
        "\n",
        "        # files with vehicle passings\n",
        "        else:\n",
        "            date_time, location, speed_kmh, sample_pos, daytime, weather, vehicle_direction, mic, channel = parts\n",
        "            vehicle, source_direction = vehicle_direction\n",
        "            is_background = False\n",
        "\n",
        "        channel = channel.replace('-BG', '')\n",
        "        speed_kmh = speed_kmh.replace('unknownKmh', 'UNK')\n",
        "        speed_kmh = speed_kmh.replace('Kmh', '')\n",
        "\n",
        "        df_dataset.append({'file': fn,\n",
        "                           'is_background': is_background,\n",
        "                           'date_time': date_time,\n",
        "                           'location': location,\n",
        "                           'speed_kmh': speed_kmh,\n",
        "                           'sample_pos': sample_pos,\n",
        "                           'daytime': daytime,\n",
        "                           'weather': weather,\n",
        "                           'vehicle': vehicle,\n",
        "                           'source_direction': source_direction,\n",
        "                           'microphone': mic,\n",
        "                           'channel': channel})\n",
        "\n",
        "    df_dataset = pd.DataFrame(df_dataset, columns=('file', 'is_background', 'date_time', 'location', 'speed_kmh', 'sample_pos', 'daytime', 'weather', 'vehicle',\n",
        "                                                   'source_direction', 'microphone', 'channel'))\n",
        "\n",
        "    return df_dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1vwNFqj2GaY"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "Baseline Model for my Bachelor Thesis\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "__author__ = 'Johannes Eder (Jo.Eder@campus.lmu.de)'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-cB239lBNBT",
        "outputId": "3c9232dc-0dd0-4a00-ed7b-f8942611dda8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkIJ1NyiBPG8",
        "outputId": "be9f2585-476f-44c7-b153-606aaf0497c7"
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ATT00001.gdoc\n",
            "'Colab Notebooks'\n",
            "'Data Science and Machine Learning.gslides'\n",
            " datasets\n",
            " models\n",
            "'ProbenBisWeihnachten (1).txt.gdoc'\n",
            " ProbenBisWeihnachten.txt.gdoc\n",
            "'Project Edwinter.gdoc'\n",
            "'Seminar Paper: Handout and Literature.gdoc'\n",
            "'Um Antwort wird gebeten (1).gform'\n",
            "'Um Antwort wird gebeten.gform'\n",
            "'User Interview.gdoc'\n",
            "'User Interviews Drink Mates'\n",
            " vorläufige.gdoc\n",
            " VVZafa183ad-b65e-4fbb-9681-0bac29b42558.rtf.gdoc\n",
            "'Wie soll unsere App heißen?_exported_on_Tue May 05 2020 17:18:32 GMT+0530 (IST).gsheet'\n",
            "'Wie soll unsere App heißen? .gform'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtqX1_Zzx6z"
      },
      "source": [
        "CLASSES = ['None','C','T', 'M', 'B']\n",
        "NORMAL_CLASSES = ['None']\n",
        "ANOMALOUS_CLASSES = ['C','T', 'M', 'B']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pch1Z3AhBSaP"
      },
      "source": [
        "class IdmtTrafficDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, annotations_file, audio_dir, audio_transformation, transformation, target_sample_rate, normal_classes):\n",
        "        self.annotations =  annotations_file if isinstance(annotations_file, pd.DataFrame) else pd.read_csv(annotations_file)\n",
        "        self.audio_dir = audio_dir\n",
        "        self.audio_transformation = audio_transformation\n",
        "        self.transformation = transformation\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        #self.classes = ['None','C','T', 'M', 'B']\n",
        "        self.normal_classes = normal_classes\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        audio_sample_path = self._get_audio_sample_path(index)\n",
        "        label = self._get_audio_sample_label(index)\n",
        "        signal, sr = torchaudio.load(audio_sample_path)\n",
        "        signal = self._resample(signal, sr) #adjust sample rates\n",
        "        # signal -> (num_channels, samples) i.e. (2, 16000)\n",
        "        signal  = self._mix_down(signal) #stereo to mono\n",
        "        signal = self.audio_transformation(signal) #(1, 16000) -> torch.Size([1, 64, 63])\n",
        "        signal = self.transformation(signal)\n",
        "        #label = self.normal_classes.index(label)\n",
        "        label = 1 if label in self.normal_classes else 0 #1 for normal 0 for anomalous\n",
        "        return signal, label\n",
        "\n",
        "    def _resample(self, signal, sr):\n",
        "        if sr != self.target_sample_rate:\n",
        "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "            signal = resampler(signal)\n",
        "        return signal\n",
        "    \n",
        "    def _mix_down(self, signal):\n",
        "        if signal.shape[0] > 1: #(2, 16000)\n",
        "            #mean operation: aggregating multiple channels\n",
        "            signal = torch.mean(signal, 0, True)\n",
        "        return signal\n",
        "\n",
        "    def _get_audio_sample_path(self, index):\n",
        "        path = os.path.join(self.audio_dir, self.annotations.iloc[index, 0])\n",
        "        return path + '.wav'\n",
        "\n",
        "    def _get_audio_sample_label(self, index):\n",
        "        return self.annotations.iloc[index, 9]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaADhdVqBWL8"
      },
      "source": [
        "SAMPLE_RATE = 22500\n",
        "N_FFT=2048 #is also window size\n",
        "HOP_LENGTH=1024\n",
        "N_MELS=128\n",
        "melspectogram = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "        n_fft=N_FFT, # Frame Size\n",
        "        hop_length=HOP_LENGTH, #here half the frame size\n",
        "        n_mels=N_MELS\n",
        "    )\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(mode='L'),\n",
        "    #transforms.Grayscale(num_output_channels=3),\n",
        "    #transforms.Resize([224, 224]),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJlQmACW3z4P"
      },
      "source": [
        "    AUDIO_DIR = \"/content/drive/My Drive/datasets/IDMT_Traffic/audio\"\n",
        "    train_annotations = \"/content/drive/My Drive/datasets/IDMT_Traffic/annotation/eusipco_2021_train.csv\"\n",
        "    test_annotatons = \"/content/drive/My Drive/datasets/IDMT_Traffic/annotation/eusipco_2021_test.csv\"\n",
        "    all_annotations_txt = \"/content/drive/My Drive/datasets/IDMT_Traffic/annotation/idmt_traffic_all.txt\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTzdntp5BcfQ"
      },
      "source": [
        "def get_train_and_val_idmt(audio_dir, train_annotations, test_annotations):\n",
        "    train_data = IdmtTrafficDataSet(train_annotations, audio_dir,melspectogram, transforms, SAMPLE_RATE)\n",
        "    test_data = IdmtTrafficDataSet(test_annotatons, audio_dir,melspectogram, transforms, SAMPLE_RATE)\n",
        "    return train_data, test_data\n",
        "\n",
        "def get_normal_and_anomalous_data(normal_classes, anomalous_classes, audio_dir, annotations, batch_size):\n",
        "    all_data = import_idmt_traffic_dataset(annotations)\n",
        "\n",
        "    normal_data = all_data[all_data.vehicle.isin(normal_classes)]\n",
        "    anomalous_data = all_data[all_data.vehicle.isin(anomalous_classes)]\n",
        "\n",
        "    train_data = normal_data.iloc[:6000, :] #test data needs to have some amount of normal data as well\n",
        "    train_data = adjust_frame_to_batch_size(train_data, batch_size)\n",
        "\n",
        "    normal_test_data = normal_data.iloc[6001:, :]\n",
        "    number_of_normal_test_sampels = len(normal_test_data)\n",
        "    print(f\"testing with {number_of_normal_test_sampels} normal samples\")\n",
        "\n",
        "    #sample same number of anomalous data to test\n",
        "    anomalous_data = anomalous_data.sample(number_of_normal_test_sampels)\n",
        "\n",
        "    frames = [anomalous_data, normal_test_data]\n",
        "    concatenated_test_data = pd.concat(frames)\n",
        "    concatenated_test_data.reset_index(drop=True, inplace=True)\n",
        "    concatenated_test_data = adjust_frame_to_batch_size(concatenated_test_data, batch_size)\n",
        "\n",
        "    normal_train_data = IdmtTrafficDataSet(train_data, audio_dir, melspectogram, transforms, SAMPLE_RATE, normal_classes)\n",
        "    test_data = IdmtTrafficDataSet(concatenated_test_data, audio_dir, melspectogram, transforms, SAMPLE_RATE, normal_classes)\n",
        "\n",
        "    return normal_train_data, test_data\n",
        "\n",
        "def adjust_frame_to_batch_size(data, batch_size):\n",
        "  if len(data) % batch_size == 0:\n",
        "    return data\n",
        "  else:\n",
        "    remainder = len(data) % batch_size\n",
        "    return data.iloc[remainder + 1:,:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71EkxTEJCXAK"
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "        #FC(Input, 64, ReLU)\n",
        "        nn.Linear(in_features=input_dim, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        #FC(64, 32, ReLU),\n",
        "        nn.Linear(in_features=64, out_features=32),\n",
        "        nn.ReLU(),\n",
        "        #FC(32, 16, ReLU)\n",
        "        nn.Linear(in_features=32, out_features=16),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        #FC(16, 32,ReLU)\n",
        "        nn.Linear(in_features=16, out_features=32),\n",
        "        nn.ReLU(),\n",
        "        #FC(32, 64, ReLU), \n",
        "        nn.Linear(in_features=32, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        #FC(64, Output, none)\n",
        "        nn.Linear(in_features=64, out_features=input_dim),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, input_data):\n",
        "    z = self.encoder(input_data)\n",
        "    output = self.decoder(z)\n",
        "    return output"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4NP5lFZKzys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db82fe55-7304-49c2-eb33-fdf33f21a5ac"
      },
      "source": [
        "LEARNING_RATE = 0.00001\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "BATCH_SIZE_VAL = 50\n",
        "\n",
        "train_data, test_data = get_normal_and_anomalous_data(NORMAL_CLASSES, ANOMALOUS_CLASSES, audio_dir=AUDIO_DIR, annotations=all_annotations_txt, batch_size=BATCH_SIZE)\n",
        "first_sample, first_label = train_data[0]\n",
        "input_dim = first_sample.shape[1] *first_sample.shape[2]\n",
        "print(f\"Train Data Shape: {first_sample.shape}\")\n",
        "print(input_dim)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "autoencoder = AutoEncoder(input_dim=input_dim)\n",
        "\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LEARNING_RATE)\n",
        "loss_func = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing with 2143 normal samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dc4hNgaN1HO"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCeOehFjOdrr"
      },
      "source": [
        "def train(model, input_dim, device, train_loader, optimizer, epoch, loss_func):\n",
        "  print(f\"Starting Epoch {epoch}\")\n",
        "  model.to(device)\n",
        "  model.train() #set mode\n",
        "  for batch_index, (data_batch, _) in enumerate(train_loader):\n",
        "    data_batch = data_batch.view(-1, input_dim).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data_batch)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = loss_func(output, data_batch)\n",
        "    loss.backward()                 \n",
        "    optimizer.step()\n",
        "    \n",
        "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_index * len(data_batch), len(train_loader.dataset),100. * batch_index / len(train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PumyQPpQVm2"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  train(autoencoder, input_dim, device, train_loader, optimizer, epoch, loss_func)\n",
        "  print(\"epoch : {}/{}\".format(epoch + 1, EPOCHS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SupaXXT2C_3"
      },
      "source": [
        "def evaluate(model, val_loader, device):\n",
        "  anom_scores = []\n",
        "  targets = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for _, data in enumerate(val_loader, 0):\n",
        "      inputs, batch_targets = data\n",
        "      inputs, batch_targets = inputs.view(-1, input_dim).to(device), batch_targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      batch_anom_scores = nn.functional.mse_loss(inputs, outputs, size_average=None, reduce=None, reduction='none') #reconstrucion error(pixelwise)\n",
        "      batch_anom_scores = [torch.sum(x) for x in batch_anom_scores] #sum up reconstruction errors \n",
        "      anom_scores.append(batch_anom_scores)\n",
        "      targets.append(batch_targets)\n",
        "    return anom_scores, targets\n",
        "\n",
        "anom_scores, targets = evaluate(autoencoder, test_loader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH_56EnnBGMS"
      },
      "source": [
        "print(len(anom_scores))\n",
        "print(anom_scores[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07OOg2dtREaE"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fp_rate, tp_rate, _ = roc_curve(targets.numpy(), anom_scores)\n",
        "roc_auc = roc_auc_score(targets, anom_scores)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fp_rate, tp_rate, color='darkorange', label=f\"ROC_AUC ={roc_auc}\")\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve of normal Class Background Noise')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpgXjlxoUXrY"
      },
      "source": [
        "print(\"Traininig finished! Saving Model...\")\n",
        "import time\n",
        "from google.colab import files\n",
        "current_time = time.asctime( time.localtime(time.time()) )\n",
        "torch.save(autoencoder.state_dict(), '/content/drive/My Drive/models/baseline/' + str(current_time))\n",
        "\n",
        "plt.savefig('/content/drive/My Drive/models/baseline/roc_graph' + str(current_time))\n",
        "\n",
        "#save hyperparams:\n",
        "with open('/content/drive/My Drive/models/baseline/hyper_params' + str(current_time) + '.txt', 'w') as f:\n",
        "  f.write(f\"Epochs: {EPOCHS}, LR: {LEARNING_RATE}, BatchSize: {BATCH_SIZE}, SAMPLE_RATE = {SAMPLE_RATE}, N_FFT/WINDOW_SIZE = {N_FFT}, HOP_LENGTH = {HOP_LENGTH}, N_MELS = {N_MELS}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}